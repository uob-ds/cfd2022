{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8290ba",
   "metadata": {},
   "source": [
    "# Simple and multiple regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2322a3c9",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Safe settings for Pandas.\n",
    "pd.set_option('mode.chained_assignment', 'raise')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94780ae2",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def standard_units(any_numbers):\n",
    "    \"\"\" Convert any array of numbers to standard units.\n",
    "    \"\"\"\n",
    "    return (any_numbers - np.mean(any_numbers))/np.std(any_numbers)\n",
    "\n",
    "def correlation(t, x, y):\n",
    "    \"\"\" Correlation of columns `x` and `y` from data frame `t`\n",
    "    \"\"\"\n",
    "    return np.mean(standard_units(t[x]) * standard_units(t[y]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f81396",
   "metadata": {},
   "source": [
    "## Back to simple regression\n",
    "\n",
    "The [multiple regression](Multiple_Regression) page introduced an extension the\n",
    "simple regression methods we saw in the [finding\n",
    "lines](../mean-slopes/finding_lines) page, and those following.\n",
    "\n",
    "Simple regression uses a single set of predictor values, and a straight line,\n",
    "to predict another set of values.\n",
    "\n",
    "For example, in the finding lines page above, we predicted the \"quality\" scores\n",
    "(on the y-axis) from the \"easiness\" scores (on the x-axis).\n",
    "\n",
    "Multiple regression takes this a step further.  Now we use more than on sets of\n",
    "values to predict another set of values.  For example, in the multiple\n",
    "regression page, we used many sets of values, such as first and second floor\n",
    "area, lot area, and others, in order to predict the house sale price.\n",
    "\n",
    "The multiple regression page followed on directly from the classification\n",
    "pages; we used multiple regression to build a model of house prices, from the\n",
    "training set, and then predicted house prices in the testing set.\n",
    "\n",
    "In this page we go back a little, to simple regression, and show how it relates\n",
    "to the multiple regression we have just done.\n",
    "\n",
    "On the way, we will start using a standard statistics library in Python, called\n",
    "StatsModels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c525ae2b",
   "metadata": {},
   "source": [
    "## Simple regression\n",
    "\n",
    "Let us return to simple regression - using one set of values (on the x axis) to\n",
    "predict another set of values (on the y axis).\n",
    "\n",
    "Here is our familiar [chronic kidney disease\n",
    "dataset](../data/chronic_kidney_disease)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f13aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckd = pd.read_csv('ckd.csv')\n",
    "ckd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288313f6",
   "metadata": {},
   "source": [
    "In our case, we restrict ourselves to the chronic kidney disease patients.\n",
    "These patients have a `1` in the `Class` column.\n",
    "\n",
    "We're also going to restrict ourselves to looking at the following measures:\n",
    "\n",
    "* `Serum Creatinine`: a measure of how well the kidney is clearing substances\n",
    "  from the blood.  When creatinine is high, it means the kidney is not clearing\n",
    "  well.  This is the general measure of kidney disease that we are interested\n",
    "  to predict.\n",
    "* `Blood Urea`: another measure of the ability of the kidney to clear\n",
    "  substances from the blood.  Urea is high in the blood when the kidneys are\n",
    "  not clearing efficiently.\n",
    "* `Hemoglobin`: healthy kidneys release a hormone *erythropoietin* that\n",
    "  stimulates production of red blood cells, and red blood cells contain the\n",
    "  *hemoglobin* molecule.  When the kidneys are damaged, they produce less\n",
    "  erythropoietin, so the body produces fewer red blood cells, and there is a\n",
    "  lower concentration of hemoglobin in the blood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11f4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data frame restricted to kidney patients and columns of interest.\n",
    "ckdp = ckd.loc[\n",
    "    ckd['Class'] == 1,\n",
    "    ['Serum Creatinine', 'Blood Urea', 'Hemoglobin']]\n",
    "# Rename the columns with shorted names.\n",
    "ckdp.columns = ['Creatinine', 'Urea', 'Hemoglobin']\n",
    "ckdp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41681407",
   "metadata": {},
   "source": [
    "First let us look at the relationship of the urea levels and the creatinine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d072788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckdp.plot.scatter('Urea', 'Creatinine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24836259",
   "metadata": {},
   "source": [
    "There is a positive correlation between these sets of values; high urea and\n",
    "high creatinine go together; both reflect the failure of the kidneys to clear\n",
    "substances from the blood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0488c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(ckdp, 'Urea', 'Creatinine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63f0ae6",
   "metadata": {},
   "source": [
    "Now recall our standard method of finding a straight line to match these two\n",
    "attributes, where we choose our straight line to minimize the sum of squared\n",
    "error between the straight line prediction of the `Creatinine` values from the\n",
    "`Urea` values, and the actual values of `Creatinine`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee4374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ss_any_line(c_s, x_values, y_values):\n",
    "    \"\"\" Sum of squares error for intercept, slope\n",
    "    \"\"\"\n",
    "    c, s = c_s\n",
    "    predicted = c + x_values * s\n",
    "    error = y_values - predicted\n",
    "    return np.sum(error ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874b649f",
   "metadata": {},
   "source": [
    "We find the least-squares straight line, using an initial guess for the slope and intercept of `[0, 0]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde8760e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "initial_guess = [0, 0]\n",
    "\n",
    "min_res = minimize(ss_any_line,\n",
    "                   initial_guess,\n",
    "                   args=(ckdp['Urea'], ckdp['Creatinine']))\n",
    "min_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f022223",
   "metadata": {},
   "source": [
    "In particular, our intercept and slope are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05f79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_res.x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73b001f",
   "metadata": {},
   "source": [
    "Compare this to the function we minimized in the [multiple\n",
    "regression](Multiple_Regression) page.  You may have noticed there, that our\n",
    "function that we minimized for calculated the *root mean square error*.\n",
    "\n",
    "The *root mean square error* is just the sum of squared error, as above,\n",
    "divided by the number of elements in the sequence, and then applying the square\n",
    "root.  Here's our function above, using root mean square error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bd1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_any_line(c_s, x_values, y_values):\n",
    "    \"\"\" Root mean square error for intercept, slope\n",
    "    \"\"\"\n",
    "    c, s = c_s\n",
    "    predicted = c + x_values * s\n",
    "    error = y_values - predicted\n",
    "    return np.sqrt(np.mean(error ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650adf68",
   "metadata": {},
   "source": [
    "Notice the difference is just in the last line of the function.  Notice too\n",
    "that the sum of square error and the root mean squared error always go in the\n",
    "same direction.  If we take any two pairs of intercept, slopes - say `c_s_1`\n",
    "and `c_s_2`, then if the sum of squares error is smaller for `c_s_1` than\n",
    "`c_s_2`, then so is the root mean squared error - and visa versa.\n",
    "\n",
    "This means we can minimize on the root mean squared error, and we are\n",
    "guaranteed to get the same result within calculation precision, as we would for\n",
    "the sum of squared error.   The `c_s` pair minimizing the root mean square\n",
    "error must be the same as the `c_s` minimizing the root mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e4d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing the sum of squares error (again).\n",
    "min_ss = minimize(ss_any_line,\n",
    "                  initial_guess,\n",
    "                  args=(ckdp['Urea'], ckdp['Creatinine']))\n",
    "min_ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75945fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizing the root mean squares error.\n",
    "min_rmse = minimize(rmse_any_line,\n",
    "                    initial_guess,\n",
    "                    args=(ckdp['Urea'], ckdp['Creatinine']))\n",
    "min_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b945087d",
   "metadata": {},
   "source": [
    "It can be useful to use the root mean square error, because the sum of squared\n",
    "errors can get very large when there are many observations, or relatively large\n",
    "values.  Using the root mean square gives less extreme values that can be\n",
    "easier for the `minimize` routine to deal with.\n",
    "\n",
    "You have already seen for this special case, of the sum of squares (or root\n",
    "mean squares) error, we can get the same answer directly with calculation.  We\n",
    "used `linregress` from `scipy.stats` to do this calculation in earlier pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06161f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import linregress\n",
    "\n",
    "linregress(ckdp['Urea'], ckdp['Creatinine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4644a1",
   "metadata": {},
   "source": [
    "Notice that the slope and the intercept are the same as those from `minimize`\n",
    "above, within the precision of the calculation, and that the `rvalue` above is\n",
    "the same as the correlation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee71d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(ckdp, 'Urea', 'Creatinine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d11899",
   "metadata": {},
   "source": [
    "## StatsModels\n",
    "\n",
    "Now it is time to introduce a major statistics package in Python,\n",
    "[StatsModels](https://www.statsmodels.org).\n",
    "\n",
    "StatsModels does many statistical calculations; among them are simple and\n",
    "multiple regression.  Statsmodels categorizes these types of simple linear\n",
    "models as \"ordinary least squares\" (OLS).\n",
    "\n",
    "Here we load the StatModels interface that uses Pandas data frames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cee146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Pandas interface to the StatsModels routines.\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ac4d45",
   "metadata": {},
   "source": [
    "Next we specify our model using a *formula*.  Read the `~` in the formula below\n",
    "as \"as a function of\".  So the formula specifies a linear (straight-line) model\n",
    "predicting `Creatinine` *as a function of* `Urea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d2d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = smf.ols(formula=\"Creatinine ~ Urea\", data=ckdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ccf42",
   "metadata": {},
   "source": [
    "Finally we *fit* the model, and show the summary of the model fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd04cc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_fit = simple_model.fit()\n",
    "simple_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc7b265",
   "metadata": {},
   "source": [
    "Notice that the `coeff` column towards the bottom of this output.  Sure enough,\n",
    "StatsModels is doing the same calculation as `linregress`, and getting the same\n",
    "answer as `minimize` with our least-squares criterion.  The 'Intercept' and\n",
    "slope for 'Urea' are the same as those we have already seen with the other\n",
    "methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5008bda",
   "metadata": {},
   "source": [
    "## Multiple regression, in steps\n",
    "\n",
    "Now we move on to trying to predict the `Creatinine` using the `Urea` *and* the\n",
    "`Hemoglobin`.  The `Urea` values and `Hemoglobin` values contain different\n",
    "information, so both values may be useful in predicting the `Creatinine`.\n",
    "\n",
    "One way to use both values is to use them step by step - first use `Urea`, and\n",
    "then use `Hemoglobin`.\n",
    "\n",
    "First we predict the `Creatinine` using just the straight-line relationship we\n",
    "have found for `Urea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8cd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the RMSE line; but all our methods gave the same line.\n",
    "intercept, slope = min_rmse.x\n",
    "creat_predicted = intercept + slope * ckdp['Urea']\n",
    "errors = ckdp['Creatinine'] - creat_predicted\n",
    "# Show the first five errors\n",
    "errors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4377180",
   "metadata": {},
   "source": [
    "We can also call these errors *residuals* in the sense they are the error\n",
    "*remaining* after removing the (straight-line) effect of `Urea`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b5df71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also call the errors - residuals.\n",
    "residuals = errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbdad99",
   "metadata": {},
   "source": [
    "The remaining root mean square error is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77a28469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root mean square error\n",
    "np.sqrt(np.mean(residuals ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac7d15b",
   "metadata": {},
   "source": [
    "Now we want to see if we can predict these residuals with the `Hemoglobin`\n",
    "values.  Let's use these residuals as our new y values, and fit a predicting\n",
    "line using `Hemoglobin`.\n",
    "\n",
    "First plot the residuals (y) against the `Hemoglobin` (x):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e9a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(ckdp['Hemoglobin'], residuals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac3860",
   "metadata": {},
   "source": [
    "Then fit a line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d826d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rmse_hgb = minimize(rmse_any_line,\n",
    "                        initial_guess,\n",
    "                        args=(ckdp['Hemoglobin'], residuals))\n",
    "min_rmse_hgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b123190",
   "metadata": {},
   "source": [
    "The results from minimize show that the line relating `Hemoglobin` and the\n",
    "residuals has a negative slope, as we would expect; more severe kidney disease\n",
    "leads to lower hemoglobin and higher creatinine.  The root mean square error\n",
    "has hardly changed, suggesting that `Hemoglobin` does not predict much, once we\n",
    "have allowed for the predictions using `Urea`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce6ef5e",
   "metadata": {},
   "source": [
    "## Multiple regression in one go\n",
    "\n",
    "Here we build the machinery as we did in the [multiple\n",
    "regression](Multiple_Regression) page.\n",
    "\n",
    "In particular, we are going to find three parameters:\n",
    "\n",
    "* An intercept;\n",
    "* A slope for the line relating `Urea` to `Creatinine`;\n",
    "* A slope for the line relating `Hemoglobin` to `Creatinine`.\n",
    "\n",
    "In the multiple regression page, we found our best-fit slopes using the\n",
    "training set, but here we will use the whole dataset.\n",
    "\n",
    "The multiple regression page did not allow for an intercept.  Here we do allow\n",
    "for an intercept.\n",
    "\n",
    "Otherwise, you will recognize much of this machinery from the multiple\n",
    "regression page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b155b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(intercept, slopes, row):\n",
    "    \"\"\" Predict a value given an intercept, slopes and corresponding row values\n",
    "    \"\"\"\n",
    "    return intercept + np.sum(slopes * np.array(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a2d405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(intercept, slopes, attributes, y_values):\n",
    "    \"\"\" Root mean square error for prediction of `y_values` from `attributes`\n",
    "\n",
    "    Use `intercept` and `slopes` multiplied by `attributes` to give prediction.\n",
    "\n",
    "    `attributes` is a data frame with numerical attributes to predict from.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    for i in np.arange(len(y_values)):\n",
    "        predicted = predict(intercept, slopes, attributes.iloc[i])\n",
    "        actual = y_values.iloc[i]\n",
    "        errors.append((actual - predicted) ** 2)\n",
    "    return np.sqrt(np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c73920",
   "metadata": {},
   "source": [
    "Here we calculate the root mean square error for an intercept of 1, and slopes\n",
    "for `Urea` and `Hemoglobin` of 0 and 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8daae0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse(1, [0, 0], ckdp.loc[:, 'Urea':], ckdp['Creatinine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65274748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_for_params(params):\n",
    "    \"\"\" RMSE for intercept, slopes contained in `params`\n",
    "\n",
    "    `params[0]` is the intercept.  `params[1:]` are the slopes.\n",
    "    \"\"\"\n",
    "    intercept = params[0]\n",
    "    slopes = params[1:]\n",
    "    return rmse(intercept,\n",
    "                slopes,\n",
    "                ckdp.loc[:, 'Urea':],\n",
    "                ckdp['Creatinine']\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5e7d57",
   "metadata": {},
   "source": [
    "Now we can get minimize to find the intercept and two slopes that minimize the\n",
    "root mean square error (and the sum of squared error):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_css = minimize(rmse_for_params, [0, 0, 0])\n",
    "min_css"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d559ae37",
   "metadata": {},
   "source": [
    "In fact, we can do this calculation more quickly, and without using a loop, by\n",
    "using array calculations.  Don't worry about the details of the function below;\n",
    "as you will soon see, it does the same calculation as the `rmse` function\n",
    "above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908be581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_fast(intercept, slopes, attributes, y_values):\n",
    "    # Make an n by s array of slopes by copying the s slopes array n times.\n",
    "    slopes_array = np.tile(slopes, [len(y_values), 1])\n",
    "    # Multiply the n by s array by the corresponding attributes.\n",
    "    slopes_fitted = np.sum(slopes_array * attributes, axis=1)\n",
    "    predicted = intercept + slopes_fitted\n",
    "    errors = y_values - predicted\n",
    "    return np.sqrt(np.mean(errors ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3132f1a",
   "metadata": {},
   "source": [
    "Here we show we get exactly the same answer with this function, as we got from the `rmse` function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73520ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_fast(1, [0, 0], ckdp.loc[:, 'Urea':], ckdp['Creatinine'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e80da9b",
   "metadata": {},
   "source": [
    "Here we use the `rmse_fast` function with our specific data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a1b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_for_params_fast(params):\n",
    "    intercept = params[0]\n",
    "    slopes = params[1:]\n",
    "    return rmse_fast(intercept, \n",
    "                slopes, \n",
    "                ckdp.loc[:, 'Urea':],\n",
    "                ckdp['Creatinine']\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca95ea5b",
   "metadata": {},
   "source": [
    "We apply the faster version of the function with minimize, to find the same\n",
    "intercept and two slopes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b5cf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_res_fast = minimize(rmse_for_params_fast, [1, 0, 0])\n",
    "min_res_fast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a70d851",
   "metadata": {},
   "source": [
    "Just as for the simple regression case, and `linregress`, we can get our\n",
    "parameters by calculation directly, in this case we were are using\n",
    "least-squares as our criterion.\n",
    "\n",
    "Don't worry about the details of the function below.  It contains the matrix\n",
    "calculation to give us the same answer as `minimize` above, as long as we are\n",
    "minimizing the root mean square error (or sum of squared error) for one or more\n",
    "slopes and an intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea97f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_regression_matrix(y_values, x_attributes):\n",
    "    intercept_col = np.ones(len(y_values))\n",
    "    X = np.column_stack([intercept_col, x_attributes])\n",
    "    return np.linalg.pinv(X) @ y_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03518aa",
   "metadata": {},
   "source": [
    "We get the same result as we do for `minimize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add5891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = multiple_regression_matrix(ckdp['Creatinine'],\n",
    "                                    ckdp.loc[:, 'Urea':])\n",
    "params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63f58e4",
   "metadata": {},
   "source": [
    "Finally, let's see StatsModels in action, to do the same calculation.\n",
    "\n",
    "Here we specify that we want to fit a linear model to `Creatinine` *as a\n",
    "function of* `Urea` *and* as a function of `Hemoglobin`.  This has the same\n",
    "meaning as above; that we will simultaneously fit the intercept, `Urea` slope\n",
    "and the `Hemoglobin` slope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a1bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_model = smf.ols(formula=\"Creatinine ~ Urea + Hemoglobin\", data=ckdp)\n",
    "multi_fit = multi_model.fit()\n",
    "multi_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ee769",
   "metadata": {},
   "source": [
    "Notice again that StatsModels is doing the same calculation as above, and\n",
    "finding the same result as `minimize`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545a089",
   "metadata": {},
   "source": [
    "## Multiple regression in 3D\n",
    "\n",
    "It can be useful to use a 3D plot to show what is going on here.  `minimize`\n",
    "and the other methods are finding these three parameters *simultaneously*:\n",
    "\n",
    "* An intercept;\n",
    "* A slope for `Urea`\n",
    "* A slope for `Hemoglobin`.\n",
    "\n",
    "The plot below shows what this looks like, in 3D.  Instead of the 2D case,\n",
    "where we are fitting the y data values (`Creatinine`) with a single straight\n",
    "line, here we are fitting the y data values with *two* straight lines.  In 3D\n",
    "these two straight lines form a plane, and we want the plane such that the sum\n",
    "of squares of the distance of the y values from the plane (plotted) is as small\n",
    "as possible.  `minimize` will change the intercept and the two slopes to move\n",
    "this plane around until it has minimized the error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b371adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell.\n",
    "import mpl_toolkits.mplot3d  # (for Matplotlib < 3.2)\n",
    "ax = plt.figure(figsize=(8,8)).add_subplot(111, projection='3d')\n",
    "ax.scatter(ckdp['Urea'],\n",
    "           ckdp['Hemoglobin'],\n",
    "           ckdp['Creatinine']\n",
    "          )\n",
    "ax.set_xlabel('Urea')\n",
    "ax.set_ylabel('Hemoglobin')\n",
    "ax.set_zlabel('Creatinine')\n",
    "intercept, urea_slope, hgb_slope = min_res_fast.x\n",
    "mx_urea, mx_hgb, mx_creat = 300, 16, 18\n",
    "ax.plot([0, mx_urea],\n",
    "        [intercept, intercept + urea_slope * mx_urea],\n",
    "        0,\n",
    "        zdir='y', color='blue', linestyle=':')\n",
    "mx_hgb = ckdp['Hemoglobin'].max()\n",
    "ax.plot([0, mx_hgb],\n",
    "        [intercept, intercept + hgb_slope * mx_hgb],\n",
    "        0,\n",
    "        zdir='x', color='black', linestyle=':')\n",
    "# Plot the fitting plane.\n",
    "plane_x = np.linspace(0, mx_urea, 50)\n",
    "plane_y = np.linspace(0, mx_hgb, 50)\n",
    "X, Y = np.meshgrid(plane_x, plane_y)\n",
    "Z = intercept + urea_slope * X + hgb_slope * Y\n",
    "ax.plot_surface(X, Y, Z, alpha=0.5)\n",
    "# Plot lines between each point and fitting plane\n",
    "for i, row in ckdp.iterrows():\n",
    "    x, y, actual = row['Urea'], row['Hemoglobin'], row['Creatinine']\n",
    "    fitted = intercept + x * urea_slope + y * hgb_slope\n",
    "    ax.plot([x, x], [y, y], [fitted, actual],\n",
    "            linestyle=':',\n",
    "            linewidth=0.5,\n",
    "            color='black')\n",
    "# Set the axis limits (and reverse y axis)\n",
    "ax.set_xlim(0, mx_urea)\n",
    "ax.set_ylim(mx_hgb, 0)\n",
    "ax.set_zlim(0, mx_creat);"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all,-language_info",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
